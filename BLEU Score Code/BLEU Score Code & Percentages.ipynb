{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhen/KmHqnrk922WcQKbXO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9o_ACsKbSxVe","executionInfo":{"status":"ok","timestamp":1723478499697,"user_tz":240,"elapsed":3908,"user":{"displayName":"abhay gupta","userId":"06781579352555862769"}},"outputId":"677050de-fd36-44d3-e418-9b8dd9c42e9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"]}],"source":["!pip install nltk"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4ZTCHolS0Pk","executionInfo":{"status":"ok","timestamp":1723478094766,"user_tz":240,"elapsed":81668,"user":{"displayName":"abhay gupta","userId":"06781579352555862769"}},"outputId":"615ac730-f9c9-40c0-9c72-563c611b7c4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","import os\n","\n","# Function to calculate BLEU score for a pair of sentences\n","def calculate_bleu(reference, hypothesis):\n","    # Check if either reference or hypothesis is NaN\n","    if pd.isna(reference) or pd.isna(hypothesis):\n","        return 0.0\n","\n","    # Tokenize the reference and hypothesis\n","    reference_tokens = reference.split()\n","    hypothesis_tokens = hypothesis.split()\n","\n","    # Use smoothing function to handle cases where n-gram precision is zero\n","    smoothing_function = SmoothingFunction().method1\n","\n","    # Calculate BLEU score\n","    score = sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smoothing_function)\n","    return score\n","\n","# Define a function to process each dataset and calculate BLEU scores\n","def process_and_calculate_bleu(file_path, columns, new_columns, output_directory, output_file_name):\n","    # Load the dataset\n","    df = pd.read_csv(file_path)\n","\n","    # Calculate BLEU scores and add them to new columns\n","    for i, (ref_col, hyp_col) in enumerate(columns):\n","        bleu_scores = []\n","        for index, row in df.iterrows():\n","            reference_text = row[ref_col]\n","            hypothesis_text = row[hyp_col]\n","            score = calculate_bleu(reference_text, hypothesis_text)\n","            bleu_scores.append(score)\n","        df[new_columns[i]] = bleu_scores\n","\n","    # Ensure the output directory exists\n","    os.makedirs(output_directory, exist_ok=True)\n","\n","    # Define the output file path for CSV\n","    output_file_path = os.path.join(output_directory, output_file_name)\n","    df.to_csv(output_file_path, index=False)\n","    print(f\"BLEU scores calculated and saved to {output_file_path}\")\n","\n","    # Calculate percentages for BLEU score thresholds and save to text file\n","    calculate_and_save_percentages(df, new_columns, output_directory)\n","\n","def calculate_and_save_percentages(df, new_columns, output_directory):\n","    # Initialize a dictionary to store percentages for each threshold\n","    thresholds = [0.7, 0.5, 0.3]\n","    percentage_results = {col: {t: 0 for t in thresholds} for col in new_columns}\n","\n","    # Calculate the percentage of scores under each threshold for each column\n","    for col in new_columns:\n","        total_count = len(df)\n","        for threshold in thresholds:\n","            count_below_threshold = (df[col] < threshold).sum()\n","            percentage_results[col][threshold] = (count_below_threshold / total_count) * 100\n","\n","    # Define the output file path for text file\n","    output_txt_path = os.path.join(output_directory, 'percentages.txt')\n","\n","    # Write the percentages to the text file\n","    with open(output_txt_path, 'w') as f:\n","        for col in new_columns:\n","            f.write(f\"{col} BLEU Score Percentages:\\n\")\n","            for threshold in thresholds:\n","                percentage = percentage_results[col][threshold]\n","                f.write(f\"  - Below {threshold:.1f}: {percentage:.2f}%\\n\")\n","            f.write(\"\\n\")\n","\n","    print(f\"Percentage scores calculated and saved to {output_txt_path}\")\n","\n","# Define the datasets and corresponding columns for BLEU score calculation\n","datasets = {\n","    'BoolQ': {\n","        'file_path': '/content/drive/MyDrive/Algoverse/New Results/GPT 4o mini Translations/Translated BoolQ.csv',\n","        'columns': [('SAE Passage', 'AAVE Passage'), ('SAE Question', 'AAVE Question')],\n","        'new_columns': ['BLEU Score Passage', 'BLEU Score Question'],\n","        'output_directory': '/content/drive/MyDrive/Algoverse/New Results/BLEU Scores/BoolQ',\n","        'output_file_name': 'boolq_bleu_scores.csv'\n","    },\n","    'COPA': {\n","        'file_path': '/content/drive/MyDrive/Algoverse/New Results/GPT 4o mini Translations/Translated Copa.csv',\n","        'columns': [\n","            ('Premise', 'Translated Premise'),\n","            ('Choice 1', 'Translated Choice 1'),\n","            ('Choice 2', 'Translated Choice 2')\n","        ],\n","        'new_columns': ['BLEU Score Premise', 'BLEU Score Choice 1', 'BLEU Score Choice 2'],\n","        'output_directory': '/content/drive/MyDrive/Algoverse/New Results/BLEU Scores/COPA',\n","        'output_file_name': 'copa_bleu_scores.csv'\n","    },\n","    'SST2': {\n","        'file_path': '/content/drive/MyDrive/Algoverse/New Results/GPT 4o mini Translations/Translated SST-2.csv',\n","        'columns': [('Original Sentence', 'Translated Sentence')],\n","        'new_columns': ['BLEU Score Sentence'],\n","        'output_directory': '/content/drive/MyDrive/Algoverse/New Results/BLEU Scores/SST-2',\n","        'output_file_name': 'sst2_bleu_scores.csv'\n","    },\n","    'WSC': {\n","        'file_path': '/content/drive/MyDrive/Algoverse/New Results/GPT 4o mini Translations/Translated WSC.csv',\n","        'columns': [('Original Paragraph', 'AAVE Paragraph')],\n","        'new_columns': ['BLEU Score Paragraph'],\n","        'output_directory': '/content/drive/MyDrive/Algoverse/New Results/BLEU Scores/WSC',\n","        'output_file_name': 'wsc_bleu_scores.csv'\n","    },\n","    'MultiRC': {\n","        'file_path': '/content/drive/MyDrive/Algoverse/New Results/GPT 4o mini Translations/Translated MultiRC.csv',\n","        'columns': [\n","            ('Paragraph', 'Translated Paragraph'),\n","            ('Question', 'Translated Question'),\n","            ('Answer Choice', 'Translated Answer Choice')\n","        ],\n","        'new_columns': ['BLEU Score Paragraph', 'BLEU Score Question', 'BLEU Score Answer Choice'],\n","        'output_directory': '/content/drive/MyDrive/Algoverse/New Results/BLEU Scores/MultiRC',\n","        'output_file_name': 'multirc_bleu_scores.csv'\n","    }\n","}\n","\n","# Process each dataset and calculate BLEU scores and percentages\n","for dataset_name, info in datasets.items():\n","    process_and_calculate_bleu(info['file_path'], info['columns'], info['new_columns'], info['output_directory'], info['output_file_name'])\n","\n","print(\"BLEU score calculations and percentage calculations completed for all datasets.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdDiC_KxUuwP","executionInfo":{"status":"ok","timestamp":1723479028835,"user_tz":240,"elapsed":5229,"user":{"displayName":"abhay gupta","userId":"06781579352555862769"}},"outputId":"1ed796a2-bc0c-4772-a3a1-8635451ff2d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/BoolQ/boolq_bleu_scores.csv\n","Percentage scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/BoolQ/percentages.txt\n","BLEU scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/COPA/copa_bleu_scores.csv\n","Percentage scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/COPA/percentages.txt\n","BLEU scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/SST-2/sst2_bleu_scores.csv\n","Percentage scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/SST-2/percentages.txt\n","BLEU scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/WSC/wsc_bleu_scores.csv\n","Percentage scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/WSC/percentages.txt\n","BLEU scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/MultiRC/multirc_bleu_scores.csv\n","Percentage scores calculated and saved to /content/drive/MyDrive/Algoverse/New Results/BLEU Scores/MultiRC/percentages.txt\n","BLEU score calculations and percentage calculations completed for all datasets.\n"]}]}]}