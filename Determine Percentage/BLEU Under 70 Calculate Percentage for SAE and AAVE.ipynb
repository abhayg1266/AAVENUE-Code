{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1UCytL8EDp54GuoNVCjEIPtjIXG8WkYW2","timestamp":1725741514826}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pandas"],"metadata":{"id":"Nlo2vQ8M8x3c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725789710683,"user_tz":-180,"elapsed":5117,"user":{"displayName":"Ece","userId":"08753317361233116923"}},"outputId":"0ce94cee-a347-43bc-aae6-60ac7f94cc6d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"oBqCI01Rnv3X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725790296268,"user_tz":-180,"elapsed":2585,"user":{"displayName":"Ece","userId":"08753317361233116923"}},"outputId":"06518452-dabf-43ee-e352-fb5a182ea830"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":25,"metadata":{"id":"owNNhO2I8tyN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725790298308,"user_tz":-180,"elapsed":486,"user":{"displayName":"Ece","userId":"08753317361233116923"}},"outputId":"72ae7520-d89d-4e95-9c7a-0d4e94789dc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["SAE Answer Accuracy: 92.24%\n","AAVE Answer Accuracy: 91.61%\n","SAE Answer Accuracy: 92.24%\n","AAVE Answer Accuracy: 91.61%\n","\n"]}],"source":["## SST-2\n","\n","import pandas as pd\n","\n","# Load the CSV file\n","file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/SST-2/sst2_under_70.csv'\n","data = pd.read_csv(file_path)\n","\n","# Ensure these column names exist in the CSV\n","required_columns = ['SAE Answer', 'AAVE Answer', 'Actual Label']\n","if not all(column in data.columns for column in required_columns):\n","    raise ValueError(\"The CSV file must contain 'SAE Answer', 'AAVE Answer', and 'Actual Label' columns.\")\n","\n","# Calculate accuracy for SAE Answer\n","sae_correct = (data['SAE Answer'] == data['Actual Label']).sum()\n","sae_accuracy = sae_correct / len(data) * 100\n","\n","# Calculate accuracy for AAVE Answer\n","aave_correct = (data['AAVE Answer'] == data['Actual Label']).sum()\n","aave_accuracy = aave_correct / len(data) * 100\n","\n","# Display results\n","print(f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\")\n","print(f\"AAVE Answer Accuracy: {aave_accuracy:.2f}%\")\n","\n","# Prepare the output text\n","output_text = f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\\nAAVE Answer Accuracy: {aave_accuracy:.2f}%\\n\"\n","\n","# Save the results to Accuracy.txt\n","output_file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/SST-2/Accuracy.txt'\n","with open(output_file_path, 'w') as f:\n","    f.write(output_text)\n","\n","# Display results\n","print(output_text)\n"]},{"cell_type":"code","source":["# BoolQ\n","\n","import pandas as pd\n","import re\n","\n","# Load the CSV file\n","file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/BoolQ/boolq_under_70.csv'\n","data = pd.read_csv(file_path)\n","\n","# Ensure these column names exist in the CSV\n","required_columns = ['Actual Label', 'SAE Answer', 'AAVE Answer']\n","if not all(column in data.columns for column in required_columns):\n","    raise ValueError(\"The CSV file must contain 'Actual Label', 'SAE Answer', and 'AAVE Answer' columns.\")\n","\n","# Function to clean and standardize answer values\n","def clean_answer(answer):\n","    # Check if the answer is already a boolean\n","    if isinstance(answer, bool):\n","        return 'true' if answer else 'false'\n","    # Convert answer to lowercase for uniform comparison\n","    answer = str(answer).strip().lower()\n","    # Use regex to determine if the answer is 'true' or 'false'\n","    if re.match(r'^true$', answer, re.IGNORECASE):\n","        return 'true'\n","    elif re.match(r'^false$', answer, re.IGNORECASE):\n","        return 'false'\n","    else:\n","        # If answer is neither 'true' nor 'false', handle accordingly\n","        raise ValueError(f\"Unexpected answer format: {answer}\")\n","\n","# Clean and standardize the answers in each column\n","data['Actual Label'] = data['Actual Label'].apply(clean_answer)\n","data['SAE Answer'] = data['SAE Answer'].apply(clean_answer)\n","data['AAVE Answer'] = data['AAVE Answer'].apply(clean_answer)\n","\n","# Calculate accuracy for SAE Answer\n","sae_correct = (data['SAE Answer'] == data['Actual Label']).sum()\n","sae_accuracy = sae_correct / len(data) * 100\n","\n","# Calculate accuracy for AAVE Answer\n","aave_correct = (data['AAVE Answer'] == data['Actual Label']).sum()\n","aave_accuracy = aave_correct / len(data) * 100\n","\n","# Display results\n","print(f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\")\n","print(f\"AAVE Answer Accuracy: {aave_accuracy:.2f}%\")\n","\n","# Prepare the output text\n","output_text = f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\\nAAVE Answer Accuracy: {aave_accuracy:.2f}%\\n\"\n","\n","# Save the results to Accuracy.txt\n","output_file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/BoolQ/Accuracy.txt'\n","with open(output_file_path, 'w') as f:\n","    f.write(output_text)\n","\n","# Display results\n","print(output_text)\n"],"metadata":{"id":"jRIMrHDLUkv1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725790302062,"user_tz":-180,"elapsed":1198,"user":{"displayName":"Ece","userId":"08753317361233116923"}},"outputId":"01363373-d2a0-4ea8-c46a-1b60d1250963"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["SAE Answer Accuracy: 90.76%\n","AAVE Answer Accuracy: 88.41%\n","SAE Answer Accuracy: 90.76%\n","AAVE Answer Accuracy: 88.41%\n","\n"]}]},{"cell_type":"code","source":["# MultiRC\n","\n","import pandas as pd\n","import re\n","\n","# Load the CSV file\n","file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/MultiRC/multirc_under_70.csv'\n","data = pd.read_csv(file_path)\n","\n","# Strip whitespace from column names\n","data.columns = data.columns.str.strip()\n","\n","# Ensure these column names exist in the CSV\n","required_columns = ['Actual Label', 'SAE Answer', 'AAVE Answer']\n","if not all(column in data.columns for column in required_columns):\n","    raise ValueError(\"The CSV file must contain 'Actual Answer', 'SAE Answer', and 'AAVE Answer' columns.\")\n","\n","# Function to clean and standardize answer values\n","def clean_answer(answer):\n","    # Check if the answer is already an integer (0 or 1)\n","    if isinstance(answer, int) and answer in (0, 1):\n","        return answer\n","    # Convert to string and use regex to find a number\n","    answer_str = str(answer)\n","    match = re.search(r'[01]', answer_str)\n","    if match:\n","        return int(match.group(0))\n","    else:\n","        # If no valid number is found, raise an error\n","        raise ValueError(f\"Unexpected answer format: {answer}\")\n","\n","# Clean and standardize the answers in each column\n","data['Actual Label'] = data['Actual Label'].apply(clean_answer)\n","data['SAE Answer'] = data['SAE Answer'].apply(clean_answer)\n","data['AAVE Answer'] = data['AAVE Answer'].apply(clean_answer)\n","\n","# Calculate accuracy for SAE Answer\n","sae_correct = (data['SAE Answer'] == data['Actual Label']).sum()\n","sae_accuracy = sae_correct / len(data) * 100\n","\n","# Calculate accuracy for AAVE Answer\n","aave_correct = (data['AAVE Answer'] == data['Actual Label']).sum()\n","aave_accuracy = aave_correct / len(data) * 100\n","\n","# Display results\n","print(f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\")\n","print(f\"AAVE Answer Accuracy: {aave_accuracy:.2f}%\")\n","\n","# Prepare the output text\n","output_text = f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\\nAAVE Answer Accuracy: {aave_accuracy:.2f}%\\n\"\n","\n","# Save the results to Accuracy.txt\n","output_file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/MultiRC/Accuracy.txt'\n","with open(output_file_path, 'w') as f:\n","    f.write(output_text)\n","\n","# Display results\n","print(output_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rH75dqwWS57","executionInfo":{"status":"ok","timestamp":1725790306603,"user_tz":-180,"elapsed":731,"user":{"displayName":"Ece","userId":"08753317361233116923"}},"outputId":"d5f8b749-3055-4d22-9044-b4e2714bc651"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["SAE Answer Accuracy: 85.54%\n","AAVE Answer Accuracy: 73.90%\n","SAE Answer Accuracy: 85.54%\n","AAVE Answer Accuracy: 73.90%\n","\n"]}]},{"cell_type":"code","source":["# COPA\n","\n","import pandas as pd\n","import re\n","\n","# Load the CSV file\n","file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/COPA/copa_under_70.csv'\n","data = pd.read_csv(file_path)\n","\n","# Strip whitespace from column names\n","data.columns = data.columns.str.strip()\n","\n","# Ensure these column names exist in the CSV\n","required_columns = ['Actual Answer', 'SAE Answer', 'AAVE Answer']\n","if not all(column in data.columns for column in required_columns):\n","    raise ValueError(\"The CSV file must contain 'Actual Answer', 'SAE Answer', and 'AAVE Answer' columns.\")\n","\n","# Function to clean and standardize answer values\n","def clean_answer(answer):\n","    # Check if the answer is already an integer (0 or 1)\n","    if isinstance(answer, int) and answer in (0, 1):\n","        return answer\n","    # Convert to string and use regex to find a number\n","    answer_str = str(answer)\n","    match = re.search(r'[01]', answer_str)\n","    if match:\n","        return int(match.group(0))\n","    else:\n","        # If no valid number is found, raise an error\n","        raise ValueError(f\"Unexpected answer format: {answer}\")\n","\n","# Clean and standardize the answers in each column\n","data['Actual Answer'] = data['Actual Answer'].apply(clean_answer)\n","data['SAE Answer'] = data['SAE Answer'].apply(clean_answer)\n","data['AAVE Answer'] = data['AAVE Answer'].apply(clean_answer)\n","\n","# Calculate accuracy for SAE Answer\n","sae_correct = (data['SAE Answer'] == data['Actual Answer']).sum()\n","sae_accuracy = sae_correct / len(data) * 100\n","\n","# Calculate accuracy for AAVE Answer\n","aave_correct = (data['AAVE Answer'] == data['Actual Answer']).sum()\n","aave_accuracy = aave_correct / len(data) * 100\n","\n","# Display results\n","print(f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\")\n","print(f\"AAVE Answer Accuracy: {aave_accuracy:.2f}%\")\n","\n","# Prepare the output text\n","output_text = f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\\nAAVE Answer Accuracy: {aave_accuracy:.2f}%\\n\"\n","\n","# Save the results to Accuracy.txt\n","output_file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/COPA/Accuracy.txt'\n","with open(output_file_path, 'w') as f:\n","    f.write(output_text)\n","\n","# Display results\n","print(output_text)"],"metadata":{"id":"JJf_MXLWmBix","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725790310463,"user_tz":-180,"elapsed":1212,"user":{"displayName":"Ece","userId":"08753317361233116923"}},"outputId":"04121513-e93d-4e5f-a0ac-87c65ca80722"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["SAE Answer Accuracy: 97.78%\n","AAVE Answer Accuracy: 95.24%\n","SAE Answer Accuracy: 97.78%\n","AAVE Answer Accuracy: 95.24%\n","\n"]}]},{"cell_type":"code","source":["## WSC\n","\n","import pandas as pd\n","\n","# Load the CSV file\n","file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/WSC/wsc_under_70.csv'\n","data = pd.read_csv(file_path)\n","\n","# Ensure these column names exist in the CSV\n","required_columns = ['Actual Label', 'SAE Answer', 'AAVE Answer']\n","if not all(column in data.columns for column in required_columns):\n","    raise ValueError(\"The CSV file must contain 'Actual Label', 'SAE Answer', and 'AAVE Answer' columns.\")\n","\n","# Calculate accuracy for SAE Answer\n","sae_correct = (data['SAE Answer'] == data['Actual Label']).sum()\n","sae_accuracy = sae_correct / len(data) * 100\n","\n","# Calculate accuracy for AAVE Answer\n","aave_correct = (data['AAVE Answer'] == data['Actual Label']).sum()\n","aave_accuracy = aave_correct / len(data) * 100\n","\n","# Display results\n","print(f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\")\n","print(f\"AAVE Answer Accuracy: {aave_accuracy:.2f}%\")\n","\n","# Prepare the output text\n","output_text = f\"SAE Answer Accuracy: {sae_accuracy:.2f}%\\nAAVE Answer Accuracy: {aave_accuracy:.2f}%\\n\"\n","\n","# Save the results to Accuracy.txt\n","output_file_path = '/content/drive/MyDrive/New Results/BLEU Under 70 Evals/Gemini-1.5-Pro/WSC/Accuracy.txt'\n","with open(output_file_path, 'w') as f:\n","    f.write(output_text)\n","\n","# Display results\n","print(output_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rn8PLLSUKT3d","executionInfo":{"status":"ok","timestamp":1725790316990,"user_tz":-180,"elapsed":835,"user":{"displayName":"Ece","userId":"08753317361233116923"}},"outputId":"3bfb2b3c-33d5-4082-c79f-bc25d2731b75"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["SAE Answer Accuracy: 51.03%\n","AAVE Answer Accuracy: 51.03%\n","SAE Answer Accuracy: 51.03%\n","AAVE Answer Accuracy: 51.03%\n","\n"]}]}]}